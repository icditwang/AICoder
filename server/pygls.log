INFO:pygls.server:Starting server on 127.0.0.1:2087
DEBUG:pygls.protocol:Received b'Content-Length: 2771\r\n\r\n{"jsonrpc":"2.0","id":0,"method":"initialize","params":{"processId":10478,"rootPath":"/Users/wangchong/Desktop/AI\xe4\xbb\xa3\xe7\xa0\x81\xe8\xa1\xa5\xe5\x85\xa8","rootUri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8","capabilities":{"workspace":{"applyEdit":true,"workspaceEdit":{"documentChanges":true,"resourceOperations":["create","rename","delete"],"failureHandling":"textOnlyTransactional"},"didChangeConfiguration":{"dynamicRegistration":true},"didChangeWatchedFiles":{"dynamicRegistration":true},"symbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]}},"executeCommand":{"dynamicRegistration":true},"configuration":true,"workspaceFolders":true},"textDocument":{"publishDiagnostics":{"relatedInformation":true},"synchronization":{"dynamicRegistration":true,"willSave":true,"willSaveWaitUntil":true,"didSave":true},"completion":{"dynamicRegistration":true,"contextSupport":true,"completionItem":{"snippetSupport":true,"commitCharactersSupport":true,"documentationFormat":["markdown","plaintext"],"deprecatedSupport":true,"preselectSupport":true},"completionItemKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]}},"hover":{"dynamicRegistration":true,"contentFormat":["markdown","plaintext"]},"signatureHelp":{"dynamicRegistration":true,"signatureInformation":{"documentationFormat":["markdown","plaintext"],"parameterInformation":{"labelOffsetSupport":true}}},"definition":{"dynamicRegistration":true,"linkSupport":true},"references":{"dynamicRegistration":true},"documentHighlight":{"dynamicRegistration":true},"documentSymbol":{"dynamicRegistration":true,"symbolKind":{"valueSet":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]},"hierarchicalDocumentSymbolSupport":true},"codeAction":{"dynamicRegistration":true,"codeActionLiteralSupport":{"codeActionKind":{"valueSet":["","quickfix","refactor","refactor.extract","refactor.inline","refactor.rewrite","source","source.organizeImports"]}}},"codeLens":{"dynamicRegistration":true},"formatting":{"dynamicRegistration":true},"rangeFormatting":{"dynamicRegistration":true},"onTypeFormatting":{"dynamicRegistration":true},"rename":{"dynamicRegistration":true,"prepareSupport":true},"documentLink":{"dynamicRegistration":true},"typeDefinition":{"dynamicRegistration":true,"linkSupport":true},"implementation":{"dynamicRegistration":true,"linkSupport":true},"colorProvider":{"dynamicRegistration":true},"foldingRange":{"dynamicRegistration":true,"rangeLimit":5000,"lineFoldingOnly":true},"declaration":{"dynamicRegistration":true,"linkSupport":true}}},"trace":"off","workspaceFolders":[{"uri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8","name":"AI\xe4\xbb\xa3\xe7\xa0\x81\xe8\xa1\xa5\xe5\x85\xa8"}]}}'
DEBUG:pygls.protocol:Request message received.
INFO:pygls.protocol:Language server initialized Object(processId=10478, rootPath='/Users/wangchong/Desktop/AI代码补全', rootUri='file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8', capabilities=Object(workspace=Object(applyEdit=True, workspaceEdit=Object(documentChanges=True, resourceOperations=['create', 'rename', 'delete'], failureHandling='textOnlyTransactional'), didChangeConfiguration=Object(dynamicRegistration=True), didChangeWatchedFiles=Object(dynamicRegistration=True), symbol=Object(dynamicRegistration=True, symbolKind=Object(valueSet=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26])), executeCommand=Object(dynamicRegistration=True), configuration=True, workspaceFolders=True), textDocument=Object(publishDiagnostics=Object(relatedInformation=True), synchronization=Object(dynamicRegistration=True, willSave=True, willSaveWaitUntil=True, didSave=True), completion=Object(dynamicRegistration=True, contextSupport=True, completionItem=Object(snippetSupport=True, commitCharactersSupport=True, documentationFormat=['markdown', 'plaintext'], deprecatedSupport=True, preselectSupport=True), completionItemKind=Object(valueSet=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])), hover=Object(dynamicRegistration=True, contentFormat=['markdown', 'plaintext']), signatureHelp=Object(dynamicRegistration=True, signatureInformation=Object(documentationFormat=['markdown', 'plaintext'], parameterInformation=Object(labelOffsetSupport=True))), definition=Object(dynamicRegistration=True, linkSupport=True), references=Object(dynamicRegistration=True), documentHighlight=Object(dynamicRegistration=True), documentSymbol=Object(dynamicRegistration=True, symbolKind=Object(valueSet=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]), hierarchicalDocumentSymbolSupport=True), codeAction=Object(dynamicRegistration=True, codeActionLiteralSupport=Object(codeActionKind=Object(valueSet=['', 'quickfix', 'refactor', 'refactor.extract', 'refactor.inline', 'refactor.rewrite', 'source', 'source.organizeImports']))), codeLens=Object(dynamicRegistration=True), formatting=Object(dynamicRegistration=True), rangeFormatting=Object(dynamicRegistration=True), onTypeFormatting=Object(dynamicRegistration=True), rename=Object(dynamicRegistration=True, prepareSupport=True), documentLink=Object(dynamicRegistration=True), typeDefinition=Object(dynamicRegistration=True, linkSupport=True), implementation=Object(dynamicRegistration=True, linkSupport=True), colorProvider=Object(dynamicRegistration=True), foldingRange=Object(dynamicRegistration=True, rangeLimit=5000, lineFoldingOnly=True), declaration=Object(dynamicRegistration=True, linkSupport=True))), trace='off', workspaceFolders=[Object(uri='file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8', name='AI代码补全')])
DEBUG:pygls.protocol:Server capabilities: {'textDocumentSync': 2, 'hoverProvider': False, 'completionProvider': <pygls.types.CompletionOptions object at 0x62e006828>, 'definitionProvider': False, 'referencesProvider': False, 'documentHighlightProvider': False, 'documentSymbolProvider': False, 'workspaceSymbolProvider': False, 'codeActionProvider': False, 'documentFormattingProvider': False, 'documentRangeFormattingProvider': False, 'renameProvider': False, 'executeCommandProvider': <pygls.types.ExecuteCommandOptions object at 0x62e006550>, 'workspace': {'workspaceFolders': {'supported': True, 'changeNotifications': True}}}
INFO:pygls.protocol:Sending data: {"id": 0, "jsonrpc": "2.0", "result": {"capabilities": {"textDocumentSync": 2, "hoverProvider": false, "completionProvider": {"resolveProvider": false, "triggerCharacters": [","]}, "definitionProvider": false, "referencesProvider": false, "documentHighlightProvider": false, "documentSymbolProvider": false, "workspaceSymbolProvider": false, "codeActionProvider": false, "documentFormattingProvider": false, "documentRangeFormattingProvider": false, "renameProvider": false, "executeCommandProvider": {"commands": ["countDownBlocking", "countDownNonBlocking", "registerCompletions", "showConfigurationAsync", "showConfigurationCallback", "showConfigurationThread", "unregisterCompletions"]}, "workspace": {"workspaceFolders": {"supported": true, "changeNotifications": true}}}}}
DEBUG:pygls.protocol:Received b'Content-Length: 52\r\n\r\n'
DEBUG:pygls.protocol:Received b'{"jsonrpc":"2.0","method":"initialized","params":{}}'
DEBUG:pygls.protocol:Notification message received.
DEBUG:pygls.protocol:Received b'Content-Length: 7077\r\n\r\n'
DEBUG:pygls.protocol:Received b'{"jsonrpc":"2.0","method":"textDocument/didOpen","params":{"textDocument":{"uri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py","languageId":"python","version":2,"text":"from pygls.features import COMPLETION\\nfrom pygls.server import LanguageServer\\nfrom pygls.types import CompletionItem, CompletionList, CompletionParams\\nimport tensorflow as tf\\nimport numpy as np\\nimport os\\nimport time\\nserver = LanguageServer()\\n\\n@server.feature(COMPLETION, trigger_characters=[\',\'])\\ndef completions(params: CompletionParams):\\n    \\"\\"\\"Returns completion items.\\"\\"\\"\\n    print(\\"completions.....\\")\\n    return CompletionList(False, [\\n        CompletionItem(\'hello\',kind=2,data=1),\\n        CompletionItem(\'world\',kind=2,data=2),\\n        CompletionItem(\'testpygls\',kind=2,data=2)\\n    ])\\ndef get_change_word(txt,i):\\n    p = i\\n    while p>=0 and txt[p] != \\" \\":\\n        p -= 1\\n    return txt[p:i]\\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\\ndef did_change(ls, params: DidChangeTextDocumentParams):\\n    \\"\\"\\"Text document did change notification.\\"\\"\\"\\n    # a = Object(textDocument=Object(uri=\'file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/test.py\', version=10), contentChanges=[Object(range=Object(start=Object(line=1, character=24), end=Object(line=1, character=26)), rangeLength=2, text=\'te\')])\\n    ls.show_message_log(\\"param_is: {}\\".format(params))\\n    file_change_content = params.contentChanges[0].text\\n    change_start_position = []\\n    change_end_position = []\\n    change_start_position.append(params.contentChanges[0].range.start.line)\\n    change_start_position.append(params.contentChanges[0].range.start.character)\\n    change_end_position.append(params.contentChanges[0].range.end.line)\\n    change_end_position.append(params.contentChanges[0].range.end.character)\\n    text_doc = ls.workspace.get_document(params.textDocument.uri)\\n    file_content = text_doc.source\\n    split = file_content.split(\'\\\\n\')\\n    changed_line_content = split[change_start_position[0]]\\n    change_world = get_change_word(changed_line_content,change_start_position[1])\\n    print(\\"change_position_is: {},{},{},{}\\".format(change_start_position[0],change_start_position[1],change_end_position[0],change_end_position[1]))\\n    # ls.show_message_log(\\"file_change_content_is: {}\\".format(file_change_content))\\n    # ls.show_message_log(\\"file_content: {}\\".format(file_content))\\n    \\n    print(\\"changed_line_content: {}\\".format(changed_line_content))\\n    print(\\"change_world---:{}\\".format(change_world))\\n    context = Completion(change_world)\\n    print(\\"context---:{}\\".format(context))    \\ndef Completion(content):\\n    path_to_file = tf.keras.utils.get_file(\'shakespeare.txt\',\\n                                           \'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\')\\n    text = open(path_to_file, \'rb\').read().decode(encoding=\'utf-8\')\\n    vocab = sorted(set(text))\\n    char2idx = {u: i for i, u in enumerate(vocab)}\\n    idx2char = np.array(vocab)\\n    text_as_int = np.array([char2idx[c] for c in text])\\n    seq_length = 100\\n    examples_per_epoch = len(text) // seq_length\\n    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\\n    sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\\n    def split_input_target(chunk):\\n        input_text = chunk[:-1]\\n        target_text = chunk[1:]\\n        return input_text, target_text\\n\\n    dataset = sequences.map(split_input_target)\\n    BATCH_SIZE = 64\\n    BUFFER_SIZE = 10000\\n    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\\n    dataset\\n    vocab_size = len(vocab)\\n    embedding_dim = 256\\n    rnn_units = 1024\\n    def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\\n        model = tf.keras.Sequential([\\n            tf.keras.layers.Embedding(vocab_size, embedding_dim,\\n                                      batch_input_shape=[batch_size, None]),\\n            tf.keras.layers.GRU(rnn_units,\\n                                return_sequences=True,\\n                                stateful=True,\\n                                recurrent_initializer=\'glorot_uniform\'),\\n            tf.keras.layers.Dense(vocab_size)\\n        ])\\n        return model\\n    model = build_model(\\n        vocab_size=len(vocab),\\n        embedding_dim=embedding_dim,\\n        rnn_units=rnn_units,\\n        batch_size=BATCH_SIZE)\\n    for input_example_batch, target_example_batch in dataset.take(1):\\n        example_batch_predictions = model(input_example_batch)\\n        # print(example_batch_predictions.shape, \\"# (batch_size, sequence_length, vocab_size)\\")\\n    sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\\n    sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\\n    sampled_indices\\n    def loss(labels, logits):\\n        return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\\n\\n    example_batch_loss = loss(target_example_batch, example_batch_predictions)\\n    model.compile(optimizer=\'adam\', loss=loss)\\n    # \xe6\xa3\x80\xe6\x9f\xa5\xe7\x82\xb9\xe4\xbf\x9d\xe5\xad\x98\xe8\x87\xb3\xe7\x9a\x84\xe7\x9b\xae\xe5\xbd\x95\\n    checkpoint_dir = \'./training_checkpoints\'\\n    # \xe6\xa3\x80\xe6\x9f\xa5\xe7\x82\xb9\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\\n    checkpoint_prefix = os.path.join(checkpoint_dir, \\"ckpt_{epoch}\\")\\n\\n    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\\n        filepath=checkpoint_prefix,\\n        save_weights_only=True)\\n\\n    EPOCHS = 6\\n\\n    model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\\n\\n    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\\n\\n    model.build(tf.TensorShape([1, None]))\\n\\n    def generate_text(model, start_string):\\n        \\n        # \xe8\xa6\x81\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xaa\xe6\x95\xb0\\n        num_generate = 20\\n\\n        # \xe5\xb0\x86\xe8\xb5\xb7\xe5\xa7\x8b\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x88\xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96\xef\xbc\x89\\n        input_eval = [char2idx[s] for s in start_string]\\n        input_eval = tf.expand_dims(input_eval, 0)\\n\\n        # \xe7\xa9\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x94\xa8\xe4\xba\x8e\xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\\n        text_generated = []\\n\\n        # \xe4\xbd\x8e\xe6\xb8\xa9\xe5\xba\xa6\xe4\xbc\x9a\xe7\x94\x9f\xe6\x88\x90\xe6\x9b\xb4\xe5\x8f\xaf\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac\\n        # \xe8\xbe\x83\xe9\xab\x98\xe6\xb8\xa9\xe5\xba\xa6\xe4\xbc\x9a\xe7\x94\x9f\xe6\x88\x90\xe6\x9b\xb4\xe4\xbb\xa4\xe4\xba\xba\xe6\x83\x8a\xe8\xae\xb6\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac\\n        # \xe5\x8f\xaf\xe4\xbb\xa5\xe9\x80\x9a\xe8\xbf\x87\xe8\xaf\x95\xe9\xaa\x8c\xe4\xbb\xa5\xe6\x89\xbe\xe5\x88\xb0\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe8\xae\xbe\xe5\xae\x9a\\n        temperature = 1.0\\n\\n        # \xe8\xbf\x99\xe9\x87\x8c\xe6\x89\xb9\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\xba 1\\n        model.reset_states()\\n        for i in range(num_generate):\\n            predictions = model(input_eval)\\n            # \xe5\x88\xa0\xe9\x99\xa4\xe6\x89\xb9\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\\n            predictions = tf.squeeze(predictions, 0)\\n\\n            # \xe7\x94\xa8\xe5\x88\x86\xe7\xb1\xbb\xe5\x88\x86\xe5\xb8\x83\xe9\xa2\x84\xe6\xb5\x8b\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\\n            predictions = predictions / temperature\\n            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\\n\\n            # \xe6\x8a\x8a\xe9\xa2\x84\xe6\xb5\x8b\xe5\xad\x97\xe7\xac\xa6\xe5\x92\x8c\xe5\x89\x8d\xe9\x9d\xa2\xe7\x9a\x84\xe9\x9a\x90\xe8\x97\x8f\xe7\x8a\xb6\xe6\x80\x81\xe4\xb8\x80\xe8\xb5\xb7\xe4\xbc\xa0\xe9\x80\x92\xe7\xbb\x99\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xbd\x9c\xe4\xb8\xba\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe8\xbe\x93\xe5\x85\xa5\\n            input_eval = tf.expand_dims([predicted_id], 0)\\n\\n            text_generated.append(idx2char[predicted_id])\\n\\n        return (start_string + \'\'.join(text_generated))\\n    return generate_text(model, start_string=content)    \\n\\nprint(\\"start_tcp.....\\")\\nserver.start_tcp(\'127.0.0.1\', 2087) "}}}'
DEBUG:pygls.protocol:Notification message received.
DEBUG:pygls.protocol:Sending notification: window/showMessage <pygls.types.ShowMessageParams object at 0x62dfe2eb8>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/showMessage", "params": {"type": 3, "message": "Text Document Did Open"}}
DEBUG:pygls.protocol:Received b'Content-Length: 311\r\n\r\n'
DEBUG:pygls.protocol:Received b'{"jsonrpc":"2.0","method":"textDocument/didChange","params":{"textDocument":{"uri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py","version":3},"contentChanges":[{"range":{"start":{"line":154,"character":36},"end":{"line":154,"character":36}},"rangeLength":0,"text":"t"}]}}'
DEBUG:pygls.protocol:Notification message received.
DEBUG:pygls.protocol:Sending notification: window/logMessage <pygls.types.LogMessageParams object at 0x62e006f98>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/logMessage", "params": {"type": 4, "message": "did_change"}}
DEBUG:pygls.protocol:Sending notification: window/logMessage <pygls.types.LogMessageParams object at 0x62e006828>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/logMessage", "params": {"type": 4, "message": "change_world---: "}}
DEBUG:pygls.protocol:Received b'Content-Length: 246\r\n\r\n'
DEBUG:pygls.protocol:Received b'{"jsonrpc":"2.0","id":1,"method":"textDocument/completion","params":{"textDocument":{"uri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py"},"position":{"line":154,"character":37},"context":{"triggerKind":1}}}'
DEBUG:pygls.protocol:Request message received.
DEBUG:pygls.protocol:Sending notification: window/logMessage <pygls.types.LogMessageParams object at 0x62dfe2f60>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/logMessage", "params": {"type": 4, "message": "completions"}}
WARNING:tensorflow:ParseError: 1:24 : 'model_checkpoint_path: "ckpt_6”': String missing ending quote: '"ckpt_6”'
WARNING:tensorflow:./training_checkpoints/checkpoint: Checkpoint ignored
ERROR:pygls.protocol:Failed to handle request 1 textDocument/completion Object(textDocument=Object(uri='file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py'), position=Object(line=154, character=37), context=Object(triggerKind=1))
Traceback (most recent call last):
  File "//anaconda3/lib/python3.7/site-packages/pygls/protocol.py", line 317, in _handle_request
    self._execute_request(msg_id, handler, params)
  File "//anaconda3/lib/python3.7/site-packages/pygls/protocol.py", line 242, in _execute_request
    self._send_response(msg_id, handler(params))
  File "/Users/wangchong/Desktop/pygls/examples/AICoder/server/server.py", line 89, in completions
    context = Completion("test")
  File "/Users/wangchong/Desktop/pygls/examples/AICoder/server/text_generation.py", line 79, in Completion
    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
  File "//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 181, in load_weights
    return super(Model, self).load_weights(filepath, by_name)
  File "//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 1139, in load_weights
    if _is_hdf5_filepath(filepath):
  File "//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 1449, in _is_hdf5_filepath
    return (filepath.endswith('.h5') or filepath.endswith('.keras') or
AttributeError: 'NoneType' object has no attribute 'endswith'
INFO:pygls.protocol:Sending data: {"id": 1, "jsonrpc": "2.0", "error": {"code": -32602, "message": "AttributeError: 'NoneType' object has no attribute 'endswith'", "data": "{'traceback': ['  File \"//anaconda3/lib/python3.7/site-packages/pygls/protocol.py\", line 317, in _handle_request\\n    self._execute_request(msg_id, handler, params)\\n', '  File \"//anaconda3/lib/python3.7/site-packages/pygls/protocol.py\", line 242, in _execute_request\\n    self._send_response(msg_id, handler(params))\\n', '  File \"/Users/wangchong/Desktop/pygls/examples/AICoder/server/server.py\", line 89, in completions\\n    context = Completion(\"test\")\\n', '  File \"/Users/wangchong/Desktop/pygls/examples/AICoder/server/text_generation.py\", line 79, in Completion\\n    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\\n', '  File \"//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 181, in load_weights\\n    return super(Model, self).load_weights(filepath, by_name)\\n', '  File \"//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1139, in load_weights\\n    if _is_hdf5_filepath(filepath):\\n', '  File \"//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1449, in _is_hdf5_filepath\\n    return (filepath.endswith(\\'.h5\\') or filepath.endswith(\\'.keras\\') or\\n']}"}}
DEBUG:pygls.protocol:Received b'Content-Length: 62\r\n\r\n{"jsonrpc":"2.0","method":"$/cancelRequest","params":{"id":1}}Content-Length: 246\r\n\r\n{"jsonrpc":"2.0","id":2,"method":"textDocument/completion","params":{"textDocument":{"uri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py"},"position":{"line":154,"character":37},"context":{"triggerKind":1}}}Content-Length: 311\r\n\r\n{"jsonrpc":"2.0","method":"textDocument/didChange","params":{"textDocument":{"uri":"file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py","version":4},"contentChanges":[{"range":{"start":{"line":154,"character":37},"end":{"line":154,"character":37}},"rangeLength":0,"text":"e"}]}}'
DEBUG:pygls.protocol:Notification message received.
WARNING:pygls.protocol:Cancel notification for unknown message id 1
DEBUG:pygls.protocol:Request message received.
DEBUG:pygls.protocol:Sending notification: window/logMessage <pygls.types.LogMessageParams object at 0x62bd8d9e8>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/logMessage", "params": {"type": 4, "message": "completions"}}
WARNING:tensorflow:ParseError: 1:24 : 'model_checkpoint_path: "ckpt_6”': String missing ending quote: '"ckpt_6”'
WARNING:tensorflow:./training_checkpoints/checkpoint: Checkpoint ignored
ERROR:pygls.protocol:Failed to handle request 2 textDocument/completion Object(textDocument=Object(uri='file:///Users/wangchong/Desktop/AI%E4%BB%A3%E7%A0%81%E8%A1%A5%E5%85%A8/testpygls.py'), position=Object(line=154, character=37), context=Object(triggerKind=1))
Traceback (most recent call last):
  File "//anaconda3/lib/python3.7/site-packages/pygls/protocol.py", line 317, in _handle_request
    self._execute_request(msg_id, handler, params)
  File "//anaconda3/lib/python3.7/site-packages/pygls/protocol.py", line 242, in _execute_request
    self._send_response(msg_id, handler(params))
  File "/Users/wangchong/Desktop/pygls/examples/AICoder/server/server.py", line 89, in completions
    context = Completion("test")
  File "/Users/wangchong/Desktop/pygls/examples/AICoder/server/text_generation.py", line 79, in Completion
    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
  File "//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 181, in load_weights
    return super(Model, self).load_weights(filepath, by_name)
  File "//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 1139, in load_weights
    if _is_hdf5_filepath(filepath):
  File "//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 1449, in _is_hdf5_filepath
    return (filepath.endswith('.h5') or filepath.endswith('.keras') or
AttributeError: 'NoneType' object has no attribute 'endswith'
INFO:pygls.protocol:Sending data: {"id": 2, "jsonrpc": "2.0", "error": {"code": -32602, "message": "AttributeError: 'NoneType' object has no attribute 'endswith'", "data": "{'traceback': ['  File \"//anaconda3/lib/python3.7/site-packages/pygls/protocol.py\", line 317, in _handle_request\\n    self._execute_request(msg_id, handler, params)\\n', '  File \"//anaconda3/lib/python3.7/site-packages/pygls/protocol.py\", line 242, in _execute_request\\n    self._send_response(msg_id, handler(params))\\n', '  File \"/Users/wangchong/Desktop/pygls/examples/AICoder/server/server.py\", line 89, in completions\\n    context = Completion(\"test\")\\n', '  File \"/Users/wangchong/Desktop/pygls/examples/AICoder/server/text_generation.py\", line 79, in Completion\\n    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\\n', '  File \"//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 181, in load_weights\\n    return super(Model, self).load_weights(filepath, by_name)\\n', '  File \"//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1139, in load_weights\\n    if _is_hdf5_filepath(filepath):\\n', '  File \"//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1449, in _is_hdf5_filepath\\n    return (filepath.endswith(\\'.h5\\') or filepath.endswith(\\'.keras\\') or\\n']}"}}
DEBUG:pygls.protocol:Notification message received.
DEBUG:pygls.protocol:Sending notification: window/logMessage <pygls.types.LogMessageParams object at 0x10427c4a8>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/logMessage", "params": {"type": 4, "message": "did_change"}}
DEBUG:pygls.protocol:Sending notification: window/logMessage <pygls.types.LogMessageParams object at 0x62e74fe48>
INFO:pygls.protocol:Sending data: {"jsonrpc": "2.0", "method": "window/logMessage", "params": {"type": 4, "message": "change_world---: t"}}
INFO:pygls.server:Shutting down the server
INFO:pygls.server:Closing the event loop.
